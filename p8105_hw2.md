p8105_hw2_qw2418
================
Qianying Wu
2023-10-03

## Problem 1

- Because of urgent timing, I’ll use the solution provided as a sample
  in the Problem 1.

We clean the 538 `pols` data, which provides information on the number
of national politicians who are democratic or republican at any given
time. There are some values for which `prez_gop` is `2` – these are
months in which Ford became President following Nixon’s resignation. In
the new `president` variable created as part of our data cleaning, we
code these as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv("data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 0 to 99. The `unemployment` data has 816
observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

``` r
# read csv
pols = read_csv("data/pols-month.csv")
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Problem 2

``` r
# Mr. Trashwheel dataset
mr_trashwheel = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 1, 
                        range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(homes_powered = 500 * weight_tons / 30, 
         trash_wheel = "Mr Trashwheel") |>
  drop_na(dumpster)

mr_trashwheel
```

    ## # A tibble: 584 × 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, trash_wheel <chr>

``` r
#  Prof Trashwheel 
prof_trashwheel = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 2) |>
  janitor::clean_names() |>
  mutate(homes_powered = 500 * weight_tons / 30, 
         year = as.character(year),
         trash_wheel = "Prof Trashwheel") |>
  drop_na(dumpster)

prof_trashwheel
```

    ## # A tibble: 106 × 14
    ##    dumpster month    year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ##  2        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ##  3        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ##  4        4 February 2017  2017-02-26 00:00:00        3.72                 15
    ##  5        5 February 2017  2017-02-28 00:00:00        1.45                 15
    ##  6        6 March    2017  2017-03-30 00:00:00        1.71                 15
    ##  7        7 April    2017  2017-04-01 00:00:00        1.82                 15
    ##  8        8 April    2017  2017-04-20 00:00:00        2.37                 15
    ##  9        9 May      2017  2017-05-10 00:00:00        2.64                 15
    ## 10       10 May      2017  2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, trash_wheel <chr>

``` r
# Gwynnda
Gwynnda = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 4) |>
  janitor::clean_names() |>
  mutate(homes_powered = 500 * weight_tons / 30,
         year = as.character(year),
         trash_wheel = "Gwynnda")|>
  drop_na(dumpster)

Gwynnda
```

    ## # A tibble: 155 × 13
    ##    dumpster month  year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 July   2021  2021-07-03 00:00:00        0.93                 15
    ##  2        2 July   2021  2021-07-07 00:00:00        2.26                 15
    ##  3        3 July   2021  2021-07-07 00:00:00        1.62                 15
    ##  4        4 July   2021  2021-07-16 00:00:00        1.76                 15
    ##  5        5 July   2021  2021-07-30 00:00:00        1.53                 15
    ##  6        6 August 2021  2021-08-11 00:00:00        2.06                 15
    ##  7        7 August 2021  2021-08-14 00:00:00        1.9                  15
    ##  8        8 August 2021  2021-08-16 00:00:00        2.16                 15
    ##  9        9 August 2021  2021-08-16 00:00:00        2.6                  15
    ## 10       10 August 2021  2021-08-17 00:00:00        3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, trash_wheel <chr>

``` r
# Join them together
trashwheel = bind_rows(mr_trashwheel, prof_trashwheel) |>
    bind_rows(x = _, y = Gwynnda)

trashwheel
```

    ## # A tibble: 845 × 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, trash_wheel <chr>

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in July of 2021?

The number of observations in the resulting dataset is 845.

1.  In particular, the mr_trashwheel dataset has 584 rows and 15
    variables. Each row represent all the trash information within a
    specific date. The dumpster information are in the time range
    between 2014 to 2022. There are different types of trash including
    plastic bottles, cigarette butts, glass bottles, etc. Their weight
    and volume are stored, with the mean of 3.2107877 tons of trash each
    day and the volume of 15.2979452 cubic yard each day.

2.  The Professor trashwheel dataset has 106 rows and 14 variables. As
    the same above, each row represent all the trash information within
    a specific date. The dumpster information are in the time range
    between 2017 to 2022. The trash’s weight and volume are stored, with
    the total trash of weight 216.26 tons, mean of 2.0401887 tons of
    trash each day and the volume of 14.5849057 cubic yard each day.

``` r
gwynnda_july_2021 <- Gwynnda |>
  filter(month == "July", year == 2021)

total_cigarette_butts <- sum(gwynnda_july_2021$cigarette_butts)

total_cigarette_butts
```

    ## [1] 16300

3.  The Gwynnda dataset has 155 rows and 13 variables. As the same
    above, each row represent all the trash information within a
    specific date. The dumpster information are in the time range
    between 2021 to 2022. The trash’s weight and volume are stored, with
    the total trash of weight 451.65 tons, mean of 2.913871 tons of
    trash each day and the volume of 14.8967742 cubic yard each day. The
    total number of cigarette butts collected by Gwynnda in July of 2021
    is 16300.

## Problem 3

### Part 1

Import, clean, and tidy the dataset of baseline demographics. Ensure
that sex and APOE4 carrier status are appropriate encoded (i.e. not
numeric), and remove any participants who do not meet the stated
inclusion criteria (i.e. no MCI at baseline).

``` r
baseline_df = 
  read_csv("data/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |>
  mutate(sex = recode(sex, "0"= "female", "1" = "male"),
         apoe4 = recode(apoe4, "0" = "non_carrier", "1" = "carrier"),
         age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset)) 
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
baseline_df
```

    ## # A tibble: 483 × 6
    ##       id current_age sex    education apoe4       age_at_onset
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>       <chr>       
    ##  1     1        63.1 female        16 carrier     <NA>        
    ##  2     2        65.6 female        20 carrier     <NA>        
    ##  3     3        62.5 male          16 carrier     66.8        
    ##  4     4        69.8 female        16 non_carrier <NA>        
    ##  5     5        66   male          16 non_carrier 68.7        
    ##  6     6        62.5 male          16 non_carrier <NA>        
    ##  7     7        66.5 male          18 non_carrier 74          
    ##  8     8        67.2 female        18 non_carrier <NA>        
    ##  9     9        66.7 female        16 non_carrier <NA>        
    ## 10    10        64.1 female        18 non_carrier <NA>        
    ## # ℹ 473 more rows

``` r
MCI = baseline_df |>
  filter(is.na(age_at_onset)|(current_age < age_at_onset))
  
MCI
```

    ## # A tibble: 479 × 6
    ##       id current_age sex    education apoe4       age_at_onset
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>       <chr>       
    ##  1     1        63.1 female        16 carrier     <NA>        
    ##  2     2        65.6 female        20 carrier     <NA>        
    ##  3     3        62.5 male          16 carrier     66.8        
    ##  4     4        69.8 female        16 non_carrier <NA>        
    ##  5     5        66   male          16 non_carrier 68.7        
    ##  6     6        62.5 male          16 non_carrier <NA>        
    ##  7     7        66.5 male          18 non_carrier 74          
    ##  8     8        67.2 female        18 non_carrier <NA>        
    ##  9     9        66.7 female        16 non_carrier <NA>        
    ## 10    10        64.1 female        18 non_carrier <NA>        
    ## # ℹ 469 more rows

Discuss important steps in the import process and relevant features of
the dataset. How many participants were recruited, and of these how many
develop MCI? What is the average baseline age? What proportion of women
in the study are APOE4 carriers?

After reading the dataset in, I first clean the data variable names,
then I use the mutate function to change sex and apoe4 variables from
numbers to characters. Later, I get rid of the no MCI dataset.

Of all participants, there are a total of 483 participants recruited.
Among these participants, 479 participants develop MCI. Their average
baseline age is 65.0286013 years old. 30 % of women in the study are
APEO4 carriers.

### Part 2

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values

``` r
amyloid_df = 
  read_csv("data/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(time_0 = baseline,
         id = study_id) |>
  pivot_longer(
    time_0:time_8,
    names_to = "period_time",
    values_to = "year"
  )
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
amyloid_df
```

    ## # A tibble: 2,435 × 3
    ##       id period_time year       
    ##    <dbl> <chr>       <chr>      
    ##  1     1 time_0      0.1105487  
    ##  2     1 time_2      <NA>       
    ##  3     1 time_4      0.109325197
    ##  4     1 time_6      0.104756131
    ##  5     1 time_8      0.107257697
    ##  6     2 time_0      0.107481183
    ##  7     2 time_2      0.109157373
    ##  8     2 time_4      0.109457839
    ##  9     2 time_6      0.105729713
    ## 10     2 time_8      0.10661845 
    ## # ℹ 2,425 more rows

Comment on the steps on the import process and the features of the
dataset.

After reading the data, I cleaned the variable names. Then, I set the
baseline variable to time_0 in order to better organize the time data.
Then, I used pivot_longer to turn the row data in a column to better
visualize the data. Last, I got rid of the missing values. There are
total number of 2435 data entry in the study with meaningful data.

### Part 3

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

``` r
combined1 = anti_join(MCI, amyloid_df)
```

    ## Joining with `by = join_by(id)`

``` r
combined2 = anti_join(amyloid_df, MCI)
```

    ## Joining with `by = join_by(id)`

``` r
combined3 = inner_join(MCI, amyloid_df)
```

    ## Joining with `by = join_by(id)`

``` r
combined1
```

    ## # A tibble: 8 × 6
    ##      id current_age sex    education apoe4       age_at_onset
    ##   <dbl>       <dbl> <chr>      <dbl> <chr>       <chr>       
    ## 1    14        58.4 female        20 non_carrier 66.2        
    ## 2    49        64.7 male          16 non_carrier 68.4        
    ## 3    92        68.6 female        20 non_carrier <NA>        
    ## 4   179        68.1 male          16 non_carrier <NA>        
    ## 5   268        61.4 female        18 carrier     67.5        
    ## 6   304        63.8 female        16 non_carrier <NA>        
    ## 7   389        59.3 female        16 non_carrier <NA>        
    ## 8   412        67   male          16 carrier     <NA>

``` r
combined2
```

    ## # A tibble: 80 × 3
    ##       id period_time year       
    ##    <dbl> <chr>       <chr>      
    ##  1    72 time_0      0.106965463
    ##  2    72 time_2      <NA>       
    ##  3    72 time_4      0.107266218
    ##  4    72 time_6      0.106665207
    ##  5    72 time_8      <NA>       
    ##  6   234 time_0      0.110521689
    ##  7   234 time_2      0.110988335
    ##  8   234 time_4      0.110318671
    ##  9   234 time_6      0.107334344
    ## 10   234 time_8      0.108868811
    ## # ℹ 70 more rows

``` r
combined3
```

    ## # A tibble: 2,355 × 8
    ##       id current_age sex    education apoe4   age_at_onset period_time year     
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>   <chr>        <chr>       <chr>    
    ##  1     1        63.1 female        16 carrier <NA>         time_0      0.1105487
    ##  2     1        63.1 female        16 carrier <NA>         time_2      <NA>     
    ##  3     1        63.1 female        16 carrier <NA>         time_4      0.109325…
    ##  4     1        63.1 female        16 carrier <NA>         time_6      0.104756…
    ##  5     1        63.1 female        16 carrier <NA>         time_8      0.107257…
    ##  6     2        65.6 female        20 carrier <NA>         time_0      0.107481…
    ##  7     2        65.6 female        20 carrier <NA>         time_2      0.109157…
    ##  8     2        65.6 female        20 carrier <NA>         time_4      0.109457…
    ##  9     2        65.6 female        20 carrier <NA>         time_6      0.105729…
    ## 10     2        65.6 female        20 carrier <NA>         time_8      0.106618…
    ## # ℹ 2,345 more rows

``` r
csv_file_path <- "data/combined.csv"
write.csv(combined3, file = csv_file_path, row.names = FALSE)
```

We want to use the anti_join function to join the dataset MCI and
amyloid twice to find the unique id in each dataset. We later use the
inner_join function to join the two dataset and find the participants
shared by both dataset. There are 8 data uniquely in the MCI dataset,
and 80 data only in the amyloid_df dataset. There are 2355 participants’
data in both MCI and amyloid_df dataset.
