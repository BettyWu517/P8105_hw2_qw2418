---
title: "p8105_hw2_qw2418"
author: "Qianying Wu"
date: "2023-10-03"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dbplyr)
```

## Problem 1

* Because of urgent timing, I'll use the solution provided as a sample in the Problem 1.

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv("data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r range(pols$year)[1]` to `r range(pols$year)[2]`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r range(snp$year)[1]` to `r range(snp$year)[2]`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.
```{r}
# read csv
pols = read_csv("data/pols-month.csv")

```

## Problem 2

```{r}
# Mr. Trashwheel dataset
mr_trashwheel = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 1, 
                        range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(homes_powered = 500 * weight_tons / 30, 
         trash_wheel = "Mr Trashwheel") |>
  drop_na(dumpster)

mr_trashwheel
  
#  Prof Trashwheel 
prof_trashwheel = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 2) |>
  janitor::clean_names() |>
  mutate(homes_powered = 500 * weight_tons / 30, 
         year = as.character(year),
         trash_wheel = "Prof Trashwheel") |>
  drop_na(dumpster)

prof_trashwheel
# Gwynnda
Gwynnda = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 4) |>
  janitor::clean_names() |>
  mutate(homes_powered = 500 * weight_tons / 30,
         year = as.character(year),
         trash_wheel = "Gwynnda")|>
  drop_na(dumpster)

Gwynnda

# Join them together
trashwheel = bind_rows(mr_trashwheel, prof_trashwheel) |>
    bind_rows(x = _, y = Gwynnda)

trashwheel
```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?


The number of observations in the resulting dataset is `r nrow(trashwheel)`. 

1. In particular, the mr_trashwheel dataset has `r nrow(mr_trashwheel)` rows and `r ncol(mr_trashwheel)` variables. Each row represent all the trash information within a specific date. The dumpster information are in the time range between 2014 to 2022. There are different types of trash including plastic bottles, cigarette butts, glass bottles, etc. Their weight and volume are stored, with the mean of `r mean(mr_trashwheel$weight_tons)` tons of trash each day and the volume of `r mean(mr_trashwheel$volume_cubic_yards)` cubic yard each day. 

2. The Professor trashwheel dataset has `r nrow(prof_trashwheel)` rows and `r ncol(prof_trashwheel)` variables. As the same above, each row represent all the trash information within a specific date. The dumpster information are in the time range between 2017 to 2022. The trash's weight and volume are stored, with the total trash of weight `r sum(prof_trashwheel$weight_tons)` tons, mean of `r mean(prof_trashwheel$weight_tons)` tons of trash each day and the volume of `r mean(prof_trashwheel$volume_cubic_yards)` cubic yard each day. 

```{R}

gwynnda_july_2021 <- Gwynnda |>
  filter(month == "July", year == 2021)

total_cigarette_butts <- sum(gwynnda_july_2021$cigarette_butts)

total_cigarette_butts

```
3. The Gwynnda dataset has `r nrow(Gwynnda)` rows and `r ncol(Gwynnda)` variables. As the same above, each row represent all the trash information within a specific date. The dumpster information are in the time range between 2021 to 2022. The trash's weight and volume are stored, with the total trash of weight `r sum(Gwynnda$weight_tons)` tons, mean of `r mean(Gwynnda$weight_tons)` tons of trash each day and the volume of `r mean(Gwynnda$volume_cubic_yards)` cubic yard each day. The total number of cigarette butts collected by Gwynnda in July of 2021 is 16300.

## Problem 3

### Part 1
Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

```{r}
baseline_df = 
  read_csv("data/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |>
  mutate(sex = recode(sex, "0"= "female", "1" = "male"),
         apoe4 = recode(apoe4, "0" = "non_carrier", "1" = "carrier"),
         age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset)) 
baseline_df

MCI = baseline_df |>
  filter(is.na(age_at_onset)|(current_age < age_at_onset))
  
MCI
```

Discuss important steps in the import process and relevant features of the dataset. How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers?

After reading the dataset in, I first clean the data variable names, then I use the mutate function to change sex and apoe4 variables from numbers to characters. Later, I get rid of the no MCI dataset.

Of all participants, there are a total of `r nrow(baseline_df)` participants recruited.
Among these participants, `r nrow(MCI)` participants develop MCI. Their average baseline age is `r mean(MCI$current_age)` years old. `r (sum(MCI$sex == "female" & MCI$apoe4 == "carrier")/sum(MCI$sex == "female")) * 100` % of women in the study are APEO4 carriers.

### Part 2
Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values

```{r}
amyloid_df = 
  read_csv("data/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(time_0 = baseline,
         id = study_id) |>
  pivot_longer(
    time_0:time_8,
    names_to = "period_time",
    values_to = "year"
  )
  
amyloid_df
```

Comment on the steps on the import process and the features of the dataset.

After reading the data, I cleaned the variable names. Then, I set the baseline variable to time_0 in order to better organize the time data. Then, I used pivot_longer to turn the row data in a column to better visualize the data. Last, I got rid of the missing values. 
There are total number of `r nrow(amyloid_df)` data entry  in the study with meaningful data. 


### Part 3

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.


```{r}
combined1 = anti_join(MCI, amyloid_df)

combined2 = anti_join(amyloid_df, MCI)

combined3 = inner_join(MCI, amyloid_df)

combined1
combined2
combined3

csv_file_path <- "data/combined.csv"
write.csv(combined3, file = csv_file_path, row.names = FALSE)



```

We want to use the anti_join function to join the dataset MCI and amyloid twice to find the unique id in each dataset. We later use the inner_join function to join the two dataset and find the participants shared by both dataset. 
There are `r nrow(combined1)` data uniquely in the MCI dataset, and `r nrow(combined2)` data only in the amyloid_df dataset. There are `r nrow(combined3)` participants' data in both MCI and amyloid_df dataset. 